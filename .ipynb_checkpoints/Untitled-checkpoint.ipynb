{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78720d-9a56-4650-b22b-7d1e250abb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Binder session alive during workshop\n",
    "import time\n",
    "import threading\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def workshop_keepalive():\n",
    "    \"\"\"Keep session alive during presentation\"\"\"\n",
    "    count = 0\n",
    "    while count < 200:  # Run for ~16 hours max\n",
    "        time.sleep(300)  # 5 minutes\n",
    "        count += 1\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Workshop session active - {time.strftime('%H:%M:%S')}\")\n",
    "        print(f\"Runtime: {count * 5} minutes\")\n",
    "        print(\"Continue with the workshop content below...\")\n",
    "\n",
    "# Start in background\n",
    "threading.Thread(target=workshop_keepalive, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783c148-740c-421e-82d6-f247fd07b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 1: DATA LOADING AND PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 1: DATA LOADING AND PREPARATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Define column names for Adult dataset\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "               'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "               'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Load the data files\n",
    "print(\"Loading Adult dataset from local files...\")\n",
    "df_train = pd.read_csv('data/adult/adult.data', names=column_names, na_values=' ?', skipinitialspace=True)\n",
    "df_test = pd.read_csv('data/adult/adult.test', names=column_names, na_values=' ?', skipinitialspace=True, skiprows=1)\n",
    "\n",
    "# Combine datasets\n",
    "df_raw = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(f\"Loaded {len(df_raw):,} records\")\n",
    "\n",
    "# Clean the data\n",
    "print(\"Cleaning and preparing data...\")\n",
    "df_clean = df_raw.dropna()\n",
    "print(f\"After removing missing values: {len(df_clean):,} records\")\n",
    "\n",
    "# Clean income column (remove periods from test set)\n",
    "df_clean['income'] = df_clean['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "# Create binary target variable (0: <=50K, 1: >50K)\n",
    "df_clean['target'] = (df_clean['income'] == '>50K').astype(int)\n",
    "\n",
    "# Create binary sex variable (0: Female, 1: Male)\n",
    "df_clean['sex_binary'] = (df_clean['sex'] == 'Male').astype(int)\n",
    "\n",
    "print(\"Data preparation complete!\")\n",
    "print(f\"Dataset shape: {df_clean.shape}\")\n",
    "print(f\"Target distribution: {df_clean['target'].value_counts().to_dict()}\")\n",
    "print(f\"Gender distribution: {df_clean['sex'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ee2b3-667e-4deb-8f4f-105ceb5521a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2: FEATURE PREPARATION FOR INCOME PREDICTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 2: FEATURE PREPARATION FOR PREDICTION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Encode categorical variables for modeling\n",
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                   'relationship', 'race', 'native-country']\n",
    "\n",
    "df_processed = df_clean.copy()\n",
    "le_dict = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_processed[f'{col}_encoded'] = le.fit_transform(df_processed[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Define feature columns (excluding target and sex for prediction fairness)\n",
    "feature_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', \n",
    "                'hours-per-week'] + [f'{col}_encoded' for col in categorical_cols] + ['sex_binary']\n",
    "\n",
    "print(f\"Features for prediction: {len(feature_cols)} variables\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"Target: 'target' (income >50K)\")\n",
    "print(f\"Protected attribute: 'sex_binary' (gender)\")\n",
    "\n",
    "# Check initial bias in outcomes\n",
    "female_high_income = df_processed[df_processed['sex_binary'] == 0]['target'].mean()\n",
    "male_high_income = df_processed[df_processed['sex_binary'] == 1]['target'].mean()\n",
    "\n",
    "print(f\"INITIAL BIAS ANALYSIS:\")\n",
    "print(f\"Female high income rate: {female_high_income:.1%}\")\n",
    "print(f\"Male high income rate: {male_high_income:.1%}\")\n",
    "print(f\"Raw disparate impact: {female_high_income / male_high_income:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1e70e-59a7-4218-936b-e5222f536235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3: CREATE AIF360 DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 3: AIF360 DATASET CREATION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Prepare final dataset for AIF360\n",
    "aif360_df = df_processed[feature_cols + ['target']].copy()\n",
    "\n",
    "# Create AIF360 StandardDataset\n",
    "dataset = StandardDataset(\n",
    "    df=aif360_df,\n",
    "    label_name='target',\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=['sex_binary'],\n",
    "    privileged_classes=[[1]],  # Male = 1\n",
    "    categorical_features=[f'{col}_encoded' for col in categorical_cols]\n",
    ")\n",
    "\n",
    "print(\"AIF360 dataset created successfully\")\n",
    "print(f\"AIF360 dataset feature shape: {dataset.features.shape}\")\n",
    "print(f\"Original feature columns: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ed23a-6749-4983-bb19-a80e6146e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_dataset, test_dataset = dataset.split([0.7], shuffle=True, seed=42)\n",
    "print(f\"Training set: {len(train_dataset.labels)} samples\")\n",
    "print(f\"Test set: {len(test_dataset.labels)} samples\")\n",
    "print(f\"Training features shape: {train_dataset.features.shape}\")\n",
    "print(f\"Test features shape: {test_dataset.features.shape}\")\n",
    "\n",
    "# Define privileged and unprivileged groups\n",
    "privileged_groups = [{'sex_binary': 1}]    # Male\n",
    "unprivileged_groups = [{'sex_binary': 0}]  # Female\n",
    "\n",
    "# Initial bias metrics on training data\n",
    "metric_orig_train = BinaryLabelDatasetMetric(\n",
    "    train_dataset,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d66aed-e43c-431a-aa46-be60eac4929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BIAS METRICS IN TRAINING DATA:\")\n",
    "disparate_impact = metric_orig_train.disparate_impact()\n",
    "statistical_parity_diff = metric_orig_train.statistical_parity_difference()\n",
    "\n",
    "print(f\"Disparate Impact: {disparate_impact:.3f}\")\n",
    "print(f\"Statistical Parity Difference: {statistical_parity_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9dd23-95ce-4b06-afd6-6198ce80aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 4: BASELINE MODEL TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 4: BASELINE MODEL TRAINING\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(\"Training baseline income prediction model...\")\n",
    "\n",
    "# Prepare data for scikit-learn\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_dataset.features)\n",
    "y_train = train_dataset.labels.ravel()\n",
    "\n",
    "# Train baseline model\n",
    "baseline_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Test baseline model\n",
    "X_test = scaler.transform(test_dataset.features)\n",
    "y_test = test_dataset.labels.ravel()\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "print(f\"Baseline Model Accuracy: {baseline_accuracy:.1%}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"Feature importance analysis:\")\n",
    "print(f\"Number of features in model: {len(baseline_model.feature_importances_)}\")\n",
    "print(f\"Number of feature names: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bb2f1-c570-4a33-b3d6-f8ba13ea75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only show feature importance if dimensions match\n",
    "if len(baseline_model.feature_importances_) == len(feature_cols):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': baseline_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"Top 5 Most Important Features:\")\n",
    "    for idx, row in feature_importance.head().iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.3f}\")\n",
    "else:\n",
    "    print(f\"Feature importance available but dimension mismatch\")\n",
    "    print(f\"Top 5 importance values: {sorted(baseline_model.feature_importances_, reverse=True)[:5]}\")\n",
    "\n",
    "# Measure bias in baseline predictions\n",
    "test_pred_baseline = test_dataset.copy()\n",
    "test_pred_baseline.labels = y_pred_baseline\n",
    "\n",
    "cm_baseline = ClassificationMetric(\n",
    "    test_dataset, test_pred_baseline,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")\n",
    "\n",
    "print(f\"\\nBASELINE MODEL BIAS METRICS:\")\n",
    "print(f\"Disparate Impact: {cm_baseline.disparate_impact():.3f}\")\n",
    "print(f\"Statistical Parity Difference: {cm_baseline.statistical_parity_difference():.3f}\")\n",
    "print(f\"Equal Opportunity Difference: {cm_baseline.equal_opportunity_difference():.3f}\")\n",
    "print(f\"Average Odds Difference: {cm_baseline.average_odds_difference():.3f}\")\n",
    "\n",
    "# Risk assessment\n",
    "di_baseline = cm_baseline.disparate_impact()\n",
    "if di_baseline < 0.8:\n",
    "    risk_level = \"HIGH RISK\"\n",
    "    print(\"HIGH LEGAL RISK: Below 80% threshold\")\n",
    "elif di_baseline < 0.9:\n",
    "    risk_level = \"MEDIUM RISK\"\n",
    "    print(\"MEDIUM RISK: Should be improved\")\n",
    "else:\n",
    "    risk_level = \"LOW RISK\"\n",
    "    print(\"ACCEPTABLE: Meets basic fairness thresholds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf3079-b07a-4f16-9e31-276a0f171a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5: BIAS MITIGATION WITH REWEIGHING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 5: BIAS MITIGATION - REWEIGHING\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "print(\"Applying Reweighing to training data...\")\n",
    "\n",
    "# Apply Reweighing algorithm\n",
    "reweighing = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")\n",
    "\n",
    "train_dataset_reweighed = reweighing.fit_transform(train_dataset)\n",
    "print(\"Reweighing applied successfully\")\n",
    "\n",
    "# Train model with reweighed data\n",
    "X_train_reweighed = scaler.fit_transform(train_dataset_reweighed.features)\n",
    "y_train_reweighed = train_dataset_reweighed.labels.ravel()\n",
    "sample_weights = train_dataset_reweighed.instance_weights\n",
    "\n",
    "reweighed_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "reweighed_model.fit(X_train_reweighed, y_train_reweighed, sample_weight=sample_weights)\n",
    "\n",
    "# Test reweighed model\n",
    "y_pred_reweighed = reweighed_model.predict(X_test)\n",
    "reweighed_accuracy = accuracy_score(y_test, y_pred_reweighed)\n",
    "\n",
    "print(f\"Reweighed Model Accuracy: {reweighed_accuracy:.1%}\")\n",
    "print(f\"Performance Change: {reweighed_accuracy - baseline_accuracy:+.1%}\")\n",
    "\n",
    "# Measure bias in reweighed predictions\n",
    "test_pred_reweighed = test_dataset.copy()\n",
    "test_pred_reweighed.labels = y_pred_reweighed\n",
    "\n",
    "cm_reweighed = ClassificationMetric(\n",
    "    test_dataset, test_pred_reweighed,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")\n",
    "\n",
    "print(f\"REWEIGHED MODEL BIAS METRICS:\")\n",
    "print(f\"Disparate Impact: {cm_reweighed.disparate_impact():.3f}\")\n",
    "print(f\"Statistical Parity Difference: {cm_reweighed.statistical_parity_difference():.3f}\")\n",
    "print(f\"Equal Opportunity Difference: {cm_reweighed.equal_opportunity_difference():.3f}\")\n",
    "print(f\"Average Odds Difference: {cm_reweighed.average_odds_difference():.3f}\")\n",
    "\n",
    "# Calculate improvements\n",
    "di_improvement = cm_reweighed.disparate_impact() - cm_baseline.disparate_impact()\n",
    "eo_improvement = abs(cm_baseline.equal_opportunity_difference()) - abs(cm_reweighed.equal_opportunity_difference())\n",
    "\n",
    "print(f\"\\nBIAS REDUCTION ACHIEVED:\")\n",
    "print(f\"Disparate Impact improvement: {di_improvement:+.3f}\")\n",
    "print(f\"Equal Opportunity improvement: {eo_improvement:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10984a-c029-401a-af10-50a1d2629345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 6: POST-PROCESSING BIAS MITIGATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 6: POST-PROCESSING BIAS MITIGATION\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "print(\"Reweighing showed minimal improvement. Trying post-processing approach...\")\n",
    "print(\"Post-processing adjusts model outputs rather than training data.\")\n",
    "\n",
    "# Try Equalized Odds Post-processing\n",
    "try:\n",
    "    from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "    \n",
    "    print(\"Applying Equalized Odds Post-processing...\")\n",
    "    \n",
    "    # Create validation dataset for post-processing\n",
    "    train_val_dataset, _ = train_dataset.split([0.5], shuffle=True, seed=42)\n",
    "    X_train_val = scaler.transform(train_val_dataset.features)\n",
    "    y_pred_train_val = baseline_model.predict(X_train_val)\n",
    "    \n",
    "    # Create dataset with baseline predictions for training post-processor\n",
    "    train_pred_dataset = train_val_dataset.copy()\n",
    "    train_pred_dataset.labels = y_pred_train_val\n",
    "    \n",
    "    # Fit post-processor\n",
    "    eq_odds = EqOddsPostprocessing(\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    eq_odds.fit(train_val_dataset, train_pred_dataset)\n",
    "    \n",
    "    # Apply post-processing to test predictions\n",
    "    test_pred_postproc = eq_odds.predict(test_pred_baseline)\n",
    "    y_pred_postproc = test_pred_postproc.labels.ravel()\n",
    "    \n",
    "    postproc_accuracy = accuracy_score(y_test, y_pred_postproc)\n",
    "    print(f\"Post-processed Model Accuracy: {postproc_accuracy:.1%}\")\n",
    "    print(f\"Performance Change from Baseline: {postproc_accuracy - baseline_accuracy:+.1%}\")\n",
    "    \n",
    "    # Measure bias in post-processed predictions\n",
    "    cm_postproc = ClassificationMetric(\n",
    "        test_dataset, test_pred_postproc,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups\n",
    "    )\n",
    "    \n",
    "    print(f\"POST-PROCESSED MODEL BIAS METRICS:\")\n",
    "    print(f\"Disparate Impact: {cm_postproc.disparate_impact():.3f}\")\n",
    "    print(f\"Statistical Parity Difference: {cm_postproc.statistical_parity_difference():.3f}\")\n",
    "    print(f\"Equal Opportunity Difference: {cm_postproc.equal_opportunity_difference():.3f}\")\n",
    "    print(f\"Average Odds Difference: {cm_postproc.average_odds_difference():.3f}\")\n",
    "    \n",
    "    # Calculate improvements from baseline\n",
    "    di_improvement_postproc = cm_postproc.disparate_impact() - cm_baseline.disparate_impact()\n",
    "    eo_improvement_postproc = abs(cm_baseline.equal_opportunity_difference()) - abs(cm_postproc.equal_opportunity_difference())\n",
    "    \n",
    "    print(f\"POST-PROCESSING BIAS REDUCTION:\")\n",
    "    print(f\"Disparate Impact improvement: {di_improvement_postproc:+.3f}\")\n",
    "    print(f\"Equal Opportunity improvement: {eo_improvement_postproc:+.3f}\")\n",
    "    \n",
    "    # Risk assessment\n",
    "    di_postproc = cm_postproc.disparate_impact()\n",
    "    if di_postproc < 0.8:\n",
    "        risk_level_postproc = \"HIGH RISK\"\n",
    "        print(\"Still HIGH LEGAL RISK: Below 80% threshold\")\n",
    "    elif di_postproc < 0.9:\n",
    "        risk_level_postproc = \"MEDIUM RISK\"\n",
    "        print(\"MEDIUM RISK: Improved but should be better\")\n",
    "    else:\n",
    "        risk_level_postproc = \"LOW RISK\"\n",
    "        print(\"ACCEPTABLE: Meets basic fairness thresholds\")\n",
    "    \n",
    "    postprocessing_available = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"EqOddsPostprocessing not available in this environment\")\n",
    "    postprocessing_available = False\n",
    "except Exception as e:\n",
    "    print(f\"Post-processing failed: {e}\")\n",
    "    print(\"This can happen with severely biased datasets like Adult\")\n",
    "    postprocessing_available = False\n",
    "\n",
    "# Try alternative post-processing approach\n",
    "if not postprocessing_available:\n",
    "    print(\"\\nTrying Calibrated Equalized Odds as alternative...\")\n",
    "    try:\n",
    "        from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "        \n",
    "        # Get prediction probabilities instead of binary predictions\n",
    "        y_pred_prob_train = baseline_model.predict_proba(X_train_val)[:, 1]\n",
    "        y_pred_prob_test = baseline_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Create datasets with probabilities\n",
    "        train_pred_prob_dataset = train_val_dataset.copy()\n",
    "        train_pred_prob_dataset.scores = y_pred_prob_train\n",
    "        \n",
    "        test_pred_prob_dataset = test_dataset.copy()\n",
    "        test_pred_prob_dataset.scores = y_pred_prob_test\n",
    "        \n",
    "        # Fit calibrated post-processor\n",
    "        cal_eq_odds = CalibratedEqOddsPostprocessing(\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups,\n",
    "            cost_constraint=\"fpr\",  # Focus on false positive rate\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        cal_eq_odds.fit(train_val_dataset, train_pred_prob_dataset)\n",
    "        \n",
    "        # Apply calibrated post-processing\n",
    "        test_pred_cal = cal_eq_odds.predict(test_pred_prob_dataset)\n",
    "        y_pred_cal = test_pred_cal.labels.ravel()\n",
    "        \n",
    "        cal_accuracy = accuracy_score(y_test, y_pred_cal)\n",
    "        print(f\"Calibrated Post-processed Model Accuracy: {cal_accuracy:.1%}\")\n",
    "        \n",
    "        # Measure bias in calibrated predictions\n",
    "        cm_cal = ClassificationMetric(\n",
    "            test_dataset, test_pred_cal,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            privileged_groups=privileged_groups\n",
    "        )\n",
    "        \n",
    "        print(f\"CALIBRATED POST-PROCESSED MODEL BIAS METRICS:\")\n",
    "        print(f\"Disparate Impact: {cm_cal.disparate_impact():.3f}\")\n",
    "        print(f\"Equal Opportunity Difference: {cm_cal.equal_opportunity_difference():.3f}\")\n",
    "        \n",
    "        di_improvement_cal = cm_cal.disparate_impact() - cm_baseline.disparate_impact()\n",
    "        print(f\"Disparate Impact improvement: {di_improvement_cal:+.3f}\")\n",
    "        \n",
    "        postprocessing_available = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Calibrated post-processing also failed: {e}\")\n",
    "        print(\"The Adult dataset's bias may be too severe for standard post-processing\")\n",
    "\n",
    "# Summary of post-processing results\n",
    "print(f\"POST-PROCESSING SUMMARY:\")\n",
    "if postprocessing_available:\n",
    "    print(\"Post-processing approach completed successfully\")\n",
    "    print(\"Compare results with pre-processing (reweighing) approach\")\n",
    "else:\n",
    "    print(\"Post-processing approaches failed - dataset bias too severe\")\n",
    "    print(\"This demonstrates the limits of algorithmic bias mitigation\")\n",
    "    print(\"Some biased datasets require more aggressive interventions or new data collection\")\n",
    "\n",
    "print(f\"WHY POST-PROCESSING MIGHT WORK BETTER:\")\n",
    "print(f\"- Adjusts final outputs rather than training process\")\n",
    "print(f\"- Can be more targeted in addressing specific fairness metrics\")\n",
    "print(f\"- Often more effective for structural bias in historical data\")\n",
    "print(f\"- Easier to tune for business requirements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9be966-e47a-41fa-b0c3-20de624c3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 7: COMPREHENSIVE COMPARISON & VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 7: MODEL COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 37)\n",
    "\n",
    "# Create comprehensive comparison\n",
    "print(\"MODEL PERFORMANCE COMPARISON:\")\n",
    "print(f\"{'Metric':<30} {'Baseline':<12} {'Reweighed':<12} {'Change':<10}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<30} {baseline_accuracy:<12.3f} {reweighed_accuracy:<12.3f} {reweighed_accuracy-baseline_accuracy:+.3f}\")\n",
    "print(f\"{'Disparate Impact':<30} {cm_baseline.disparate_impact():<12.3f} {cm_reweighed.disparate_impact():<12.3f} {di_improvement:+.3f}\")\n",
    "print(f\"{'Statistical Parity Diff':<30} {cm_baseline.statistical_parity_difference():<12.3f} {cm_reweighed.statistical_parity_difference():<12.3f} {cm_reweighed.statistical_parity_difference()-cm_baseline.statistical_parity_difference():+.3f}\")\n",
    "print(f\"{'Equal Opportunity Diff':<30} {cm_baseline.equal_opportunity_difference():<12.3f} {cm_reweighed.equal_opportunity_difference():<12.3f} {cm_reweighed.equal_opportunity_difference()-cm_baseline.equal_opportunity_difference():+.3f}\")\n",
    "print(f\"{'Average Odds Diff':<30} {cm_baseline.average_odds_difference():<12.3f} {cm_reweighed.average_odds_difference():<12.3f} {cm_reweighed.average_odds_difference()-cm_baseline.average_odds_difference():+.3f}\")\n",
    "\n",
    "# Group-specific performance analysis\n",
    "print(f\"GROUP-SPECIFIC PERFORMANCE ANALYSIS:\")\n",
    "print(f\"{'Group Performance':<25} {'Baseline':<12} {'Reweighed':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Female TPR':<25} {cm_baseline.true_positive_rate(privileged=False):<12.3f} {cm_reweighed.true_positive_rate(privileged=False):<12.3f}\")\n",
    "print(f\"{'Male TPR':<25} {cm_baseline.true_positive_rate(privileged=True):<12.3f} {cm_reweighed.true_positive_rate(privileged=True):<12.3f}\")\n",
    "print(f\"{'Female FPR':<25} {cm_baseline.false_positive_rate(privileged=False):<12.3f} {cm_reweighed.false_positive_rate(privileged=False):<12.3f}\")\n",
    "print(f\"{'Male FPR':<25} {cm_baseline.false_positive_rate(privileged=True):<12.3f} {cm_reweighed.false_positive_rate(privileged=True):<12.3f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Disparate Impact Comparison\n",
    "models = ['Baseline', 'Reweighed']\n",
    "di_values = [cm_baseline.disparate_impact(), cm_reweighed.disparate_impact()]\n",
    "colors = ['red' if x < 0.8 else 'orange' if x < 0.9 else 'green' for x in di_values]\n",
    "\n",
    "bars1 = ax1.bar(models, di_values, color=colors, alpha=0.7)\n",
    "ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='Legal Threshold (0.8)')\n",
    "ax1.axhline(y=1.0, color='green', linestyle='--', alpha=0.7, label='Perfect Fairness (1.0)')\n",
    "ax1.set_ylabel('Disparate Impact')\n",
    "ax1.set_title('Disparate Impact: Legal Compliance')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars1, di_values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.3f}', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Multiple Fairness Metrics\n",
    "metrics_names = ['Stat Parity', 'Equal Opp', 'Avg Odds']\n",
    "baseline_vals = [abs(cm_baseline.statistical_parity_difference()),\n",
    "                abs(cm_baseline.equal_opportunity_difference()),\n",
    "                abs(cm_baseline.average_odds_difference())]\n",
    "reweighed_vals = [abs(cm_reweighed.statistical_parity_difference()),\n",
    "                 abs(cm_reweighed.equal_opportunity_difference()),\n",
    "                 abs(cm_reweighed.average_odds_difference())]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.7, color='red')\n",
    "ax2.bar(x + width/2, reweighed_vals, width, label='Reweighed', alpha=0.7, color='blue')\n",
    "ax2.set_xlabel('Fairness Metrics (Absolute Values)')\n",
    "ax2.set_ylabel('Metric Values')\n",
    "ax2.set_title('Multiple Fairness Metrics Comparison')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(metrics_names)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Group-specific True Positive Rates\n",
    "groups = ['Female', 'Male']\n",
    "tpr_baseline = [cm_baseline.true_positive_rate(privileged=False), cm_baseline.true_positive_rate(privileged=True)]\n",
    "tpr_reweighed = [cm_reweighed.true_positive_rate(privileged=False), cm_reweighed.true_positive_rate(privileged=True)]\n",
    "\n",
    "x_groups = np.arange(len(groups))\n",
    "ax3.bar(x_groups - width/2, tpr_baseline, width, label='Baseline', alpha=0.7, color='red')\n",
    "ax3.bar(x_groups + width/2, tpr_reweighed, width, label='Reweighed', alpha=0.7, color='blue')\n",
    "ax3.set_xlabel('Gender Groups')\n",
    "ax3.set_ylabel('True Positive Rate')\n",
    "ax3.set_title('Equal Opportunity: TPR by Gender')\n",
    "ax3.set_xticks(x_groups)\n",
    "ax3.set_xticklabels(groups)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Performance vs Fairness Trade-off\n",
    "ax4.scatter(cm_baseline.disparate_impact(), baseline_accuracy, \n",
    "           s=100, color='red', label='Baseline', alpha=0.7)\n",
    "ax4.scatter(cm_reweighed.disparate_impact(), reweighed_accuracy, \n",
    "           s=100, color='blue', label='Reweighed', alpha=0.7)\n",
    "ax4.axvline(x=0.8, color='red', linestyle='--', alpha=0.7, label='Legal Threshold')\n",
    "ax4.set_xlabel('Disparate Impact (Fairness)')\n",
    "ax4.set_ylabel('Accuracy (Performance)')\n",
    "ax4.set_title('Performance vs Fairness Trade-off')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db196df-6427-4ae2-9667-899089140339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 8: EXECUTIVE SUMMARY & RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"SECTION 8: EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"BUSINESS IMPACT ANALYSIS:\")\n",
    "print(f\"Performance Trade-off: {reweighed_accuracy - baseline_accuracy:+.1%} accuracy\")\n",
    "print(f\"Bias Reduction: {di_improvement:+.3f} disparate impact improvement\")\n",
    "\n",
    "# Determine recommendation\n",
    "if cm_reweighed.disparate_impact() >= 0.8 and reweighed_accuracy >= baseline_accuracy * 0.98:\n",
    "    recommendation = \"DEPLOY: Bias reduced with minimal performance impact\"\n",
    "elif cm_reweighed.disparate_impact() >= 0.8:\n",
    "    recommendation = \"DEPLOY WITH CAUTION: Bias reduced but some performance loss\"\n",
    "elif di_improvement > 0.1:\n",
    "    recommendation = \"PARTIAL SUCCESS: Significant improvement but still needs work\"\n",
    "else:\n",
    "    recommendation = \"ALTERNATIVE NEEDED: Try different bias mitigation approach\"\n",
    "\n",
    "print(f\"RECOMMENDation: {recommendation}\")\n",
    "\n",
    "print(f\"KEY FAIRNESS METRICS FOR INCOME PREDICTION:\")\n",
    "print(f\"1. Disparate Impact: Legal compliance (should be > 0.8)\")\n",
    "print(f\"2. Equal Opportunity: Fair treatment of qualified candidates\")\n",
    "print(f\"3. Statistical Parity: May not be appropriate for income prediction\")\n",
    "\n",
    "print(f\"WHY EQUAL OPPORTUNITY IS BETTER FOR INCOME PREDICTION:\")\n",
    "print(f\"- Focuses on fair treatment of people who SHOULD get high income\")\n",
    "print(f\"- Allows for legitimate differences due to qualifications\")\n",
    "print(f\"- More business-appropriate than strict statistical parity\")\n",
    "\n",
    "print(f\"NEXT STEPS:\")\n",
    "print(f\"1. Consider Equal Opportunity as primary metric\")\n",
    "print(f\"2. Test other AIF360 algorithms (post-processing, adversarial debiasing)\")\n",
    "print(f\"3. Implement bias monitoring in production\")\n",
    "print(f\"4. Regular model audits for bias drift\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"WORKSHOP COMPLETE: AIF360 INCOME PREDICTION BIAS MITIGATION\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712211b-df57-4421-a2eb-8f7e0ec4bce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41178828-77c9-4ab7-850a-393a9d1b56d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcc350-d071-4973-bf64-11a25aed46a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405e2e9-6eb2-4c94-af71-223b19e46ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
